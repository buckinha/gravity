7-7-15
import numpy
import FireGirlTests
import HKB_Heuristics
from FireGirlPolicy import *
from MDP_PolicyOptimizer import *

bounds = [None]*11
for i in range(11):
  bounds[i] = [-1,1]
bounds[0] = [-10,10]
x0 = [0,0,0,0,0,0,0,0,0,0,0]
trials = FireGirlTests.FireGirlTrials()



___ I ___
Non-zero coin-toss



b=[None]*11
for i in range(11):
   b[i] = 0.0001

pol1 = FireGirlPolicy()
pol1.setParams(b)

pw1 = trials.MDP_generate_standard_set(policy=pol1, supp_var_cost=100, supp_fixed_cost=100)

values = []
supp_decs = []
for pw in pw1:
   values.append(pw.net_value)
   supp_decs.append(pw.actions_1_taken)


numpy.mean(values)
1307090.76
numpy.mean(supp_decs)
85.269999999999996

values
[1182802.0, 1256686.0, 1293478.0, 1134476.0, 1290975.0, 1346439.0, 1151604.0, 1544638.0, 1461449.0, 1378630.0, 1392329.0, 1401771.0, 1439950.0, 1546818.0, 1402735.0, 1132873.0, 1377657.0, 1211998.0, 1124516.0, 1404921.0, 1435697.0, 1129557.0, 1154727.0, 1254676.0, 1343985.0, 1402901.0, 1422492.0, 1354058.0, 1418249.0, 1332669.0, 1346019.0, 1583857.0, 1238448.0, 1280631.0, 1103402.0, 1171540.0, 1281693.0, 1377976.0, 1130639.0, 1456533.0, 1618741.0, 1400473.0, 1161586.0, 1307498.0, 1551682.0, 1196289.0, 1259033.0, 1250012.0, 1428417.0, 1274516.0, 1408615.0, 1219989.0, 1250595.0, 1263383.0, 1412615.0, 1415249.0, 1513551.0, 1579134.0, 1366362.0, 1284196.0, 1262598.0, 1286631.0, 1121233.0, 1327663.0, 1479728.0, 1286413.0, 1346700.0, 1286325.0, 1264174.0, 1218926.0, 1135482.0, 1356848.0, 1344817.0, 1350451.0, 924495.0, 1119177.0, 1179541.0, 1361372.0, 1056203.0, 1179072.0, 1356261.0, 1252206.0, 1214854.0, 1392981.0, 1353418.0, 1422275.0, 1497009.0, 1473588.0, 1172132.0, 1236844.0, 1075630.0, 1380098.0, 1171219.0, 1097753.0, 1155178.0, 1451325.0, 1285230.0, 1262509.0, 1501137.0, 1211150.0]
supp_decs
[89, 81, 87, 87, 83, 82, 87, 83, 87, 83, 81, 83, 83, 83, 79, 87, 90, 90, 90, 81, 82, 91, 81, 79, 87, 87, 78, 83, 92, 83, 83, 77, 86, 90, 82, 88, 87, 81, 93, 86, 91, 87, 81, 88, 84, 83, 86, 87, 87, 84, 92, 88, 82, 91, 83, 82, 89, 82, 85, 81, 88, 85, 87, 86, 86, 87, 83, 88, 83, 90, 80, 86, 86, 90, 88, 87, 80, 86, 86, 91, 82, 88, 86, 84, 83, 86, 87, 83, 86, 80, 86, 88, 82, 85, 85, 82, 86, 85, 85, 90]




opt1 = MDP_PolicyOptimizer(11)
opt1.pathway_set = pw1
opt1.save_pathways("7-7-15_I.pathways")
opt1.normalize_pathways()

TA1 = HKB_Heuristics.threshold(opt1.calc_obj_fn, x0, bounds, iter_cap=700)
..new global best: val=-1.29316755223e+18, iter=687
ITERATIONS COMPLETE
Initial Value: 0.0  at solution: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Final Value: -1.29316755223e+18  at solution: [0.7708985632236048, 1, 0.1280615474396173, 0.9096551209750249, -0.5378314979780264, 0.1403790263801562, 0.011849788107761577, -0.22542381679423315, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]

TA1 = HKB_Heuristics.threshold(opt1.calc_obj_fn, TA1, bounds, iter_cap=200)
..new global best: val=-1.16380460306e+18, iter=0
..new global best: val=-1.37742509463e+18, iter=1
..new global best: val=-1.52026717573e+18, iter=52
..new global best: val=-1.70479511541e+18, iter=89
..new global best: val=-2.14296569072e+18, iter=158
..new global best: val=-2.63181438622e+18, iter=178
ITERATIONS COMPLETE
Initial Value: -1.29316755223e+18  at solution: [0.7708985632236048, 1, 0.1280615474396173, 0.9096551209750249, -0.5378314979780264, 0.1403790263801562, 0.011849788107761577, -0.22542381679423315, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]
Final Value: -2.63181438622e+18  at solution: [0.8077546726358052, 1, 0.20514273989989143, 0.9325393898437752, -0.5378314979780264, 0.33222107851744476, 0.011849788107761577, -0.22542381679423315, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]

TA1 = HKB_Heuristics.threshold(opt1.calc_obj_fn, TA1, bounds, iter_cap=200)
BEGINNING THRESHOLD ACCEPTANCE ALGORITHM
..new global best: val=-2.07410759753e+18, iter=0
..new global best: val=-2.50567956991e+18, iter=4
..new global best: val=-2.80099446163e+18, iter=151
..new global best: val=-3.09078813796e+18, iter=156
..new global best: val=-3.67565749124e+18, iter=159
..new global best: val=-4.16001290579e+18, iter=166
..new global best: val=-4.5771260624e+18, iter=168
..new global best: val=-5.64655573915e+18, iter=188
..new global best: val=-6.47471134065e+18, iter=193
..new global best: val=-7.60822736667e+18, iter=195
ITERATIONS COMPLETE
Initial Value: -2.63181438622e+18  at solution: [0.8077546726358052, 1, 0.20514273989989143, 0.9325393898437752, -0.5378314979780264, 0.33222107851744476, 0.011849788107761577, -0.22542381679423315, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]
Final Value: -7.60822736667e+18  at solution: [0.8930363043087154, 0.9846577019507683, 0.20514273989989143, 0.9325393898437752, -0.5378314979780264, 0.6216064384376206, 0.011849788107761577, -0.43889470371755634, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]

TA1 = HKB_Heuristics.threshold(opt1.calc_obj_fn, TA1, bounds, iter_cap=500)
BEGINNING THRESHOLD ACCEPTANCE ALGORITHM
..new global best: val=-7.60520439395e+18, iter=0
..new global best: val=-9.63286342926e+18, iter=24
..new global best: val=-1.09144724003e+19, iter=50
..new global best: val=-1.41499716391e+19, iter=72
..new global best: val=-1.58153916756e+19, iter=78
..new global best: val=-1.89983501312e+19, iter=81
..new global best: val=-2.47255862564e+19, iter=92
..new global best: val=-2.76312412374e+19, iter=124
..new global best: val=-3.06883292686e+19, iter=125
..new global best: val=-3.44114540249e+19, iter=161
..new global best: val=-3.81603914587e+19, iter=169
..new global best: val=-4.60495603428e+19, iter=184
..new global best: val=-5.44347665764e+19, iter=200
..new global best: val=-6.41837816526e+19, iter=201
..new global best: val=-7.70182698038e+19, iter=206
..new global best: val=-8.52497390298e+19, iter=215
..new global best: val=-9.66558941401e+19, iter=229
..new global best: val=-1.10672192813e+20, iter=243
..new global best: val=-1.49017317568e+20, iter=272
..new global best: val=-1.77303946818e+20, iter=285
..new global best: val=-2.17201051155e+20, iter=302
..new global best: val=-2.70709069169e+20, iter=342
..new global best: val=-3.09843453545e+20, iter=344
..new global best: val=-3.45836720362e+20, iter=357
..new global best: val=-3.84288758583e+20, iter=361
..new global best: val=-4.3357724915e+20, iter=388
..new global best: val=-5.15324098426e+20, iter=395
ITERATIONS COMPLETE
Initial Value: -7.60822736667e+18  at solution: [0.8930363043087154, 0.9846577019507683, 0.20514273989989143, 0.9325393898437752, -0.5378314979780264, 0.6216064384376206, 0.011849788107761577, -0.43889470371755634, -0.39432727354292296, -0.45772940842373516, -0.5527846490169057]
Final Value: -5.15324098426e+20  at solution: [1.3523311389455044, 0.9846577019507683, 0.5391144196598519, 1, -0.8667200437539362, 0.9983967963063788, 0.011849788107761577, -0.43889470371755634, -0.34004696211758906, -0.45772940842373516, -0.5527846490169057]


pol2=FireGirlPolicy()
pol2.setParams(TA1)
pw2 = trials.MDP_generate_standard_set(policy=pol2, supp_var_cost=100, supp_fixed_cost=100)
vals = []
supps = []
for pw in pw2:
  vals.append(pw.net_value)
  supps.append(pw.actions_1_taken)

vals
[1073228.0, 1206572.0, 1129942.0, 928274.0, 1190569.0, 1337552.0, 1139070.0, 1467671.0, 1310525.0, 1344996.0, 1144617.0, 1375570.0, 1341632.0, 1540011.0, 1265684.0, 1028855.0, 1359655.0, 1165676.0, 1118760.0, 1340120.0, 1427785.0, 1107117.0, 1103652.0, 1146367.0, 1170771.0, 1363022.0, 1327923.0, 1161023.0, 1414869.0, 1303694.0, 1341092.0, 1560648.0, 1222838.0, 1282247.0, 957453.0, 1092374.0, 1222395.0, 1240287.0, 1131148.0, 1438873.0, 1405634.0, 1347229.0, 1153319.0, 1305087.0, 1346077.0, 1179830.0, 1238471.0, 1191059.0, 1168999.0, 1242480.0, 1383012.0, 1074728.0, 1244461.0, 1214726.0, 1393748.0, 1171132.0, 1418732.0, 1300887.0, 1319588.0, 1165375.0, 1258555.0, 1238446.0, 1121675.0, 1245969.0, 1451564.0, 1228631.0, 1195483.0, 1185352.0, 1268318.0, 1217411.0, 1103317.0, 1351719.0, 1260701.0, 1292462.0, 898436.0, 1074360.0, 1172763.0, 1207125.0, 1051805.0, 1135385.0, 1205788.0, 1160007.0, 1183559.0, 1182367.0, 1202240.0, 1373082.0, 1398902.0, 1399173.0, 1106759.0, 1193237.0, 1065440.0, 1117297.0, 1140632.0, 1064566.0, 1084383.0, 1273095.0, 1183793.0, 1152502.0, 1347330.0, 1209460.0]
supps
[97, 92, 95, 95, 94, 95, 96, 96, 95, 97, 91, 94, 98, 93, 97, 92, 98, 95, 95, 90, 94, 96, 95, 96, 96, 91, 93, 95, 98, 96, 97, 89, 94, 96, 95, 96, 98, 96, 95, 95, 98, 96, 89, 96, 94, 94, 95, 95, 97, 91, 94, 99, 93, 98, 95, 97, 98, 97, 95, 96, 89, 97, 96, 95, 94, 97, 97, 99, 97, 96, 94, 92, 95, 97, 92, 97, 95, 91, 99, 96, 95, 96, 96, 93, 98, 97, 94, 94, 99, 92, 94, 98, 93, 97, 96, 95, 92, 92, 98, 94]

numpy.mean(vals)
1230922.2
numpy.std(vals)
125962.48221133149
numpy.mean(supps)
95.109999999999999


opt1.calc_fprime()
